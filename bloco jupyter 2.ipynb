{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cafe7eb8",
   "metadata": {},
   "source": [
    "# Notebook para Processar PDFs de Escalas Cirúrgicas\n",
    "\n",
    "Este notebook permite o upload de arquivos PDF de escalas cirúrgicas, processamento dos dados e geração de relatórios de procedimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ea8f5",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas Necessárias\n",
    "\n",
    "Importe as bibliotecas essenciais para manipulação de arquivos, processamento de PDFs, análise de dados e widgets para upload de arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime, time\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, FileLink\n",
    "import ipywidgets as widgets\n",
    "import shutil\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec1c6c",
   "metadata": {},
   "source": [
    "## 2. Definir Classes de Processamento\n",
    "\n",
    "Inclua todas as classes do pipeline adaptadas para uso em notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de logging para suprimir warnings desnecessários\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "\n",
    "class BaseProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def process(self, *args, **kwargs) -> Any:\n",
    "        pass\n",
    "\n",
    "class PDFScheduleParser(BaseProcessor):\n",
    "    def __init__(self, pdf_dir: str):\n",
    "        super().__init__()\n",
    "        self.pdf_dir = pdf_dir\n",
    "        self.paths = glob.glob(os.path.join(self.pdf_dir, '*.pdf'))\n",
    "\n",
    "    def process(self) -> Dict[str, Dict[str, Dict[str, List[str]]]]:\n",
    "        content: Dict[str, Dict[str, Dict[str, List[str]]]] = {}\n",
    "        for i, path in enumerate(self.paths, 1):\n",
    "            filename = os.path.basename(path)\n",
    "            content[filename] = self._parse_single(path)\n",
    "            print(f'{i}/{len(self.paths)}. {filename}')\n",
    "        return content\n",
    "\n",
    "    def _parse_single(self, path: str) -> Dict[str, Dict[str, List[str]]]:\n",
    "        pages_by_date: Dict[str, Dict[str, List[str]]] = {}\n",
    "        current_block = None\n",
    "        buffer: List[str] = []\n",
    "        current_date: Optional[str] = None\n",
    "\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text() or ''\n",
    "                lines = text.splitlines()\n",
    "                if len(lines) < 6:\n",
    "                    continue\n",
    "\n",
    "                match = re.search(r\"(\\d{2}/\\d{2}/\\d{4})\", lines[3])\n",
    "                if not match:\n",
    "                    continue\n",
    "                current_date = match.group(1)\n",
    "                pages_by_date.setdefault(current_date, {})\n",
    "\n",
    "                content_lines = lines[4:]\n",
    "                if len(content_lines) > 2:\n",
    "                    content_lines = content_lines[:-2]\n",
    "\n",
    "                unwanted = [\n",
    "                    'SOULMV', 'Relatório de Mapa Cirúrgico', 'Data: ',\n",
    "                    'GRUPO SÃO PIETRO', 'HOSPITAL BANCO DE OLHOS',\n",
    "                    'MV | SoulMV',\n",
    "                    'Cirurgia Lateralidade Convênio / Plano Sub-Plano Status Autorização',\n",
    "                    'Hora Aviso Atend. Tipo Paciente Idade Telefone Leito UTI Rad. Prestador\\\\Atividade'\n",
    "                ]\n",
    "                content_lines = [l for l in content_lines if not any(u in l for u in unwanted)]\n",
    "\n",
    "                for line in content_lines:\n",
    "                    if line.startswith(\"Centro Cirúrgico : \"):\n",
    "                        if current_block and buffer:\n",
    "                            pages_by_date[current_date].setdefault(current_block, []).extend(buffer)\n",
    "                        current_block = line.replace(\"Centro Cirúrgico : \", \"\").strip()\n",
    "                        buffer = []\n",
    "                    elif current_block:\n",
    "                        buffer.append(line)\n",
    "\n",
    "        if current_date and current_block and buffer:\n",
    "            pages_by_date[current_date].setdefault(current_block, []).extend(buffer)\n",
    "\n",
    "        return pages_by_date\n",
    "\n",
    "class SalaSplitter(BaseProcessor):\n",
    "    def process(self, block_lines: List[str], prefix: str = \"Sala : \") -> Dict[int, List[str]]:\n",
    "        salas: Dict[int, List[str]] = {}\n",
    "        current: Optional[int] = None\n",
    "        buffer: List[str] = []\n",
    "\n",
    "        for line in block_lines:\n",
    "            if line.startswith(prefix):\n",
    "                if current is not None:\n",
    "                    salas[current] = buffer\n",
    "                try:\n",
    "                    current = int(line.split()[-1])\n",
    "                except ValueError:\n",
    "                    current = -1\n",
    "                buffer = []\n",
    "            elif current is not None:\n",
    "                buffer.append(line)\n",
    "\n",
    "        if current is not None:\n",
    "            salas[current] = buffer\n",
    "        return salas\n",
    "\n",
    "class SurgeryExtractor(BaseProcessor):\n",
    "    def process(self, sala_lines: List[str]) -> Dict[str, Dict[str, Any]]:\n",
    "        blocks = self._extract_blocks(sala_lines)\n",
    "        by_time = self._map_by_time(blocks)\n",
    "        parsed: Dict[str, Dict[str, Any]] = {}\n",
    "        for time, lines in by_time.items():\n",
    "            parsed[time] = self._parse_block(time, lines)\n",
    "        return parsed\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_blocks(lines: List[str]) -> List[List[str]]:\n",
    "        blocks: List[List[str]] = []\n",
    "        current: List[str] = []\n",
    "        open_block = False\n",
    "        for l in lines:\n",
    "            if re.match(r\"^\\d{2}:\\d{2}\", l):\n",
    "                if current:\n",
    "                    blocks.append(current)\n",
    "                current = [l]\n",
    "                open_block = True\n",
    "            elif open_block:\n",
    "                current.append(l)\n",
    "                if l.startswith(\"Tipo(s) de Anestesia:\"):\n",
    "                    blocks.append(current)\n",
    "                    current = []\n",
    "                    open_block = False\n",
    "        if current:\n",
    "            blocks.append(current)\n",
    "        return blocks\n",
    "\n",
    "    @staticmethod\n",
    "    def _map_by_time(blocks: List[List[str]]) -> Dict[str, List[str]]:\n",
    "        by_time: Dict[str, List[str]] = {}\n",
    "        for blk in blocks:\n",
    "            m = re.match(r\"^(\\d{2}:\\d{2})\", blk[0])\n",
    "            key = m.group(1) if m else f\"UNKNOWN_{len(by_time)}\"\n",
    "            by_time[key] = blk\n",
    "        return by_time\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_block(time: str, lines: List[str]) -> Dict[str, Any]:\n",
    "        result = {\n",
    "            'time': time,\n",
    "            'filename': None,\n",
    "            'centro': None,\n",
    "            'patient_name': None,\n",
    "            'age': None,\n",
    "            'phone': None,\n",
    "            'surgeon': None,\n",
    "            'anesthesist': None,\n",
    "            'procedures': None,\n",
    "            'anesthesia_type': None,\n",
    "            'convenio': None,\n",
    "            'observacao': None,\n",
    "            'aviso': None,\n",
    "            'tipo': None,\n",
    "            'cod_paciente': None,\n",
    "            'lines': lines\n",
    "        }\n",
    "        if not lines:\n",
    "            return result\n",
    "\n",
    "        tokens = lines[0].split()\n",
    "        sim_nao_pairs = {'Sim Sim', 'Sim Não', 'Não Sim', 'Não Não'}\n",
    "        pair_idx = -1\n",
    "        for i in range(len(tokens) - 1):\n",
    "            if f\"{tokens[i]} {tokens[i+1]}\" in sim_nao_pairs:\n",
    "                pair_idx = i\n",
    "                break\n",
    "\n",
    "        if pair_idx >= 0:\n",
    "            result['aviso'] = tokens[1]\n",
    "            result['tipo'] = tokens[2]\n",
    "            result['cod_paciente'] = tokens[3]\n",
    "            result['surgeon'] = ' '.join(tokens[pair_idx+2:])\n",
    "            name_tokens: List[str] = []\n",
    "            age: Optional[int] = None\n",
    "            phone_tokens: List[str] = []\n",
    "            for j in range(4, pair_idx):\n",
    "                tok = tokens[j]\n",
    "                if tok.isdigit() and age is None:\n",
    "                    age = int(tok)\n",
    "                elif age is None:\n",
    "                    name_tokens.append(tok)\n",
    "                else:\n",
    "                    phone_tokens.append(tok)\n",
    "            result['patient_name'] = ' '.join(name_tokens) or None\n",
    "            result['age'] = age\n",
    "            result['phone'] = ' '.join(phone_tokens) or None\n",
    "\n",
    "        for line in reversed(lines):\n",
    "            if line.startswith(\"Observação:\"):\n",
    "                result['observacao'] = line.replace(\"Observação:\", \"\").strip()\n",
    "                break\n",
    "        for line in reversed(lines):\n",
    "            if line.startswith(\"Tipo(s) de Anestesia:\"):\n",
    "                result['anesthesia_type'] = line.replace(\"Tipo(s) de Anestesia:\", \"\").strip()\n",
    "                break\n",
    "\n",
    "        laterality_keywords = ['Esquerda', 'Direita', 'Bilateral', 'Não Se Aplica']\n",
    "        unwanted_keywords = ['Observação:', 'DIREITO', 'ESQUERDO']\n",
    "        for line in lines[::-1][1:-1]:\n",
    "            if not any(k in line for k in laterality_keywords+unwanted_keywords):\n",
    "                parts = line.split()\n",
    "                if len(parts) == 1:\n",
    "                    result['patient_name'] = (result.get('patient_name') or '') + ' ' + parts[0]\n",
    "                else:\n",
    "                    result['anesthesist'] = line\n",
    "\n",
    "        procedures: List[str] = []\n",
    "        status_keywords = ['Autorizado', 'Não Cadastrado']\n",
    "        for line in lines:\n",
    "            for kw in laterality_keywords:\n",
    "                if kw in line:\n",
    "                    before = line.split(kw)[0].strip()\n",
    "                    procedures.append(before)\n",
    "                    try:\n",
    "                        start = line.find(kw) + len(kw)\n",
    "                        aft = line[start:].strip()\n",
    "                        for st in status_keywords:\n",
    "                            if st in aft:\n",
    "                                result['convenio'] = aft.split(st)[0].strip()\n",
    "                                break\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    break\n",
    "        if procedures:\n",
    "            result['procedures'] = ' + '.join(sorted(procedures))\n",
    "\n",
    "        return result\n",
    "\n",
    "class InMemoryFlattener(BaseProcessor):\n",
    "    def process(self, content: Dict[str, Dict[str, Dict[str, List[str]]]]) -> Dict[str, Dict[int, Dict[str, Dict[str, Any]]]]:\n",
    "        flattened: Dict[str, Dict[int, Dict[str, Dict[str, Any]]]] = {}\n",
    "        for filename, dates in content.items():\n",
    "            for date, centros in dates.items():\n",
    "                flattened.setdefault(date, {})\n",
    "                for centro, salas in centros.items():\n",
    "                    for sala, surgeries in salas.items():\n",
    "                        flattened[date].setdefault(sala, {})\n",
    "                        for time, surgery in surgeries.items():\n",
    "                            rec = surgery.copy()\n",
    "                            rec['filename'] = filename\n",
    "                            rec['centro'] = centro\n",
    "                            flattened[date][sala][time] = rec\n",
    "        return flattened\n",
    "\n",
    "class ScheduleReorderer(BaseProcessor):\n",
    "    def process(self, data: Dict[str, Dict[int, Dict[str, Dict[str, Any]]]]) -> OrderedDict:\n",
    "        ordered: OrderedDict = OrderedDict()\n",
    "        for date in sorted(data.keys(), key=lambda d: datetime.strptime(d, '%d/%m/%Y')):\n",
    "            ordered[date] = OrderedDict()\n",
    "            for room in sorted(data[date].keys()):\n",
    "                ordered[date][room] = OrderedDict()\n",
    "                for t in sorted(data[date][room].keys(), key=lambda tm: datetime.strptime(tm, '%H:%M')):\n",
    "                    ordered[date][room][t] = data[date][room][t]\n",
    "        return ordered\n",
    "\n",
    "class DurationCalculator(BaseProcessor):\n",
    "    def process(self, ordered: OrderedDict) -> OrderedDict:\n",
    "        for date, rooms in ordered.items():\n",
    "            for room, slots in rooms.items():\n",
    "                times = list(slots.keys())\n",
    "                for i, t in enumerate(times):\n",
    "                    start_dt = datetime.strptime(t, '%H:%M')\n",
    "                    if i + 1 < len(times):\n",
    "                        next_dt = datetime.strptime(times[i+1], '%H:%M')\n",
    "                        minutes = (next_dt - start_dt).total_seconds() / 60\n",
    "                    else:\n",
    "                        minutes = None\n",
    "                    slots[t]['duration_minutes'] = minutes\n",
    "        return ordered\n",
    "\n",
    "class ShiftWeekdayAnnotator(BaseProcessor):\n",
    "    WEEKDAY_MAP = {\n",
    "        0: \"2 - Segunda-feira\",\n",
    "        1: \"3 - Terça-feira\",\n",
    "        2: \"4 - Quarta-feira\",\n",
    "        3: \"5 - Quinta-feira\",\n",
    "        4: \"6 - Sexta-feira\",\n",
    "        5: \"7 - Sábado\",\n",
    "        6: \"1- Domingo\",\n",
    "    }\n",
    "\n",
    "    def process(self, ordered: \"OrderedDict[str, Dict[int, Dict[str, Any]]]\") \\\n",
    "            -> \"OrderedDict[str, Dict[int, Dict[str, Any]]]\":\n",
    "        for date_str, rooms in ordered.items():\n",
    "            date_obj = datetime.strptime(date_str, \"%d/%m/%Y\")\n",
    "            weekday = self.WEEKDAY_MAP[date_obj.weekday()]\n",
    "\n",
    "            for room, slots in rooms.items():\n",
    "                for time_str, surgery in slots.items():\n",
    "                    t = datetime.strptime(time_str, \"%H:%M\").time()\n",
    "                    if t < time(12, 0):\n",
    "                        turno = \"1 - Manhã\"\n",
    "                    elif t < time(17, 0):\n",
    "                        turno = \"2 - Tarde\"\n",
    "                    else:\n",
    "                        turno = \"3 - Noite\"\n",
    "                    surgery[\"turno\"] = turno\n",
    "                    surgery[\"weekday\"] = weekday\n",
    "\n",
    "        return ordered\n",
    "\n",
    "class DataFrameSerializer(BaseProcessor):\n",
    "    def process(self, duration_dict: OrderedDict, path: str = 'escala_bloco.csv') -> pd.DataFrame:\n",
    "        records: List[Dict[str, Any]] = []\n",
    "        for date, rooms in duration_dict.items():\n",
    "            for room, slots in rooms.items():\n",
    "                for time, surgery in slots.items():\n",
    "                    rec = surgery.copy()\n",
    "                    rec['date'] = date\n",
    "                    rec['room'] = room\n",
    "                    rec['time'] = time\n",
    "                    records.append(rec)\n",
    "        df = pd.DataFrame(records)\n",
    "        desired_order = [\n",
    "            'filename','centro',\n",
    "            'date', 'weekday',\n",
    "            'room','turno', 'time', \n",
    "            'surgeon','duration_minutes','procedures','anesthesia_type','convenio',\n",
    "            'observacao','anesthesist',\n",
    "            'patient_name','age','phone',\n",
    "            'aviso','tipo','cod_paciente','lines'\n",
    "        ]\n",
    "        cols = [c for c in desired_order if c in df.columns]\n",
    "        df = df[cols]\n",
    "        df.to_csv(path, index=False)\n",
    "        return df\n",
    "\n",
    "class InsightsGenerator(BaseProcessor):\n",
    "    def process(self, df: pd.DataFrame) -> None:\n",
    "        df_u1 = df.drop_duplicates(subset=['surgeon','procedures','anesthesia_type','duration_minutes'])\n",
    "        lines: List[str] = []\n",
    "        for surgeon, grp in df_u1.groupby('surgeon'):\n",
    "            lines.append(f\"Dr(a) {surgeon}:\")\n",
    "            for _, row in grp.iterrows():\n",
    "                dur = row['duration_minutes']\n",
    "                dur_text = f\"{int(dur)} minutos\" if pd.notna(dur) else \"quanto tempo\"\n",
    "                anesth = row['anesthesia_type'] or ''\n",
    "                anesth_text = f\"sob anestesia {anesth}\" if anesth else ''\n",
    "                lines.append(f\"  Realiza o procedimento {row['procedures']} {anesth_text} em {dur_text}?\")\n",
    "            lines.append(\"\")\n",
    "        with open('procedimentos.txt','w',encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        df_u2 = df.drop_duplicates(subset=['procedures','anesthesia_type','duration_minutes'])\n",
    "        lines2: List[str] = []\n",
    "        for i, ((proc, anes), grp) in enumerate(df_u2.groupby(['procedures','anesthesia_type'])):\n",
    "            lines2.append(f\"{i}. {proc} sob {anes}:\")\n",
    "            for _, row in grp.iterrows():\n",
    "                dur = row['duration_minutes']\n",
    "                dur_text = f\"{int(dur)} minutos\" if pd.notna(dur) else \"quanto tempo\"\n",
    "                lines2.append(f\"  O procedimento {row['procedures']} leva {dur_text}?\")\n",
    "            lines2.append(\"\")\n",
    "        with open('procedimentos_duracao.txt','w',encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(lines2))\n",
    "\n",
    "class ScheduleController:\n",
    "    def __init__(self, pdf_dir: str):\n",
    "        self.parser = PDFScheduleParser(pdf_dir)\n",
    "        self.splitter = SalaSplitter()\n",
    "        self.extractor = SurgeryExtractor()\n",
    "        self.flattener = InMemoryFlattener()\n",
    "        self.reorderer = ScheduleReorderer()\n",
    "        self.durationer = DurationCalculator()\n",
    "        self.annotator  = ShiftWeekdayAnnotator()\n",
    "        self.serializer = DataFrameSerializer()\n",
    "        self.insights = InsightsGenerator()\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        raw = self.parser.process()\n",
    "        for filename, dates in raw.items():\n",
    "            for date, centros in dates.items():\n",
    "                for centro, lines in centros.items():\n",
    "                    salas = self.splitter.process(lines)\n",
    "                    parsed_salas: Dict[int, Dict[str, Dict[str, Any]]] = {}\n",
    "                    for sala, sala_lines in salas.items():\n",
    "                        parsed_salas[sala] = self.extractor.process(sala_lines)\n",
    "                    raw[filename][date][centro] = parsed_salas\n",
    "        flat = self.flattener.process(raw)\n",
    "        ordered = self.reorderer.process(flat)\n",
    "        durationed = self.durationer.process(ordered)\n",
    "        annotated = self.annotator.process(durationed)\n",
    "        df = self.serializer.process(annotated)\n",
    "        self.insights.process(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5657e0",
   "metadata": {},
   "source": [
    "## 3. Upload de Arquivos PDF\n",
    "\n",
    "Utilize o widget abaixo para enviar arquivos PDF. Eles serão salvos em um diretório temporário para processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório temporário para uploads\n",
    "upload_dir = os.path.join(tempfile.gettempdir(), \"pdf_uploads_bfx\")\n",
    "os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "# Widget de upload\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.pdf',\n",
    "    multiple=True,\n",
    "    description='Enviar PDFs'\n",
    ")\n",
    "\n",
    "def save_uploaded_files(uploaded, dest_dir):\n",
    "    for fname, fileinfo in uploaded.value.items():\n",
    "        with open(os.path.join(dest_dir, fname), 'wb') as f:\n",
    "            f.write(fileinfo['content'])\n",
    "\n",
    "display(uploader)\n",
    "\n",
    "upload_button = widgets.Button(description=\"Salvar arquivos enviados\")\n",
    "output_upload = widgets.Output()\n",
    "\n",
    "def on_upload_clicked(b):\n",
    "    with output_upload:\n",
    "        output_upload.clear_output()\n",
    "        if uploader.value:\n",
    "            save_uploaded_files(uploader, upload_dir)\n",
    "            print(f\"{len(uploader.value)} arquivo(s) salvo(s) em {upload_dir}\")\n",
    "        else:\n",
    "            print(\"Nenhum arquivo enviado.\")\n",
    "\n",
    "upload_button.on_click(on_upload_clicked)\n",
    "display(upload_button, output_upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91464727",
   "metadata": {},
   "source": [
    "## 4. Processar PDFs Enviados\n",
    "\n",
    "Execute o pipeline de processamento nos arquivos enviados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar PDFs enviados\n",
    "controller = ScheduleController(upload_dir)\n",
    "df_result = controller.run()\n",
    "print(\"Processamento concluído!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef62f5",
   "metadata": {},
   "source": [
    "## 5. Visualizar DataFrame Resultante\n",
    "\n",
    "Visualize os dados extraídos dos PDFs em formato de tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a442dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as primeiras linhas do DataFrame resultante\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df_result.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14616814",
   "metadata": {},
   "source": [
    "## 6. Gerar Relatórios de Insights\n",
    "\n",
    "Visualize trechos dos relatórios gerados sobre procedimentos e suas durações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e24dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir trechos dos relatórios gerados\n",
    "def show_report_excerpt(filepath, n=10):\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        print(f\"Trecho de {filepath}:\")\n",
    "        print(\"\".join(lines[:n]))\n",
    "        display(FileLink(filepath))\n",
    "    else:\n",
    "        print(f\"Arquivo {filepath} não encontrado.\")\n",
    "\n",
    "show_report_excerpt('procedimentos.txt', n=15)\n",
    "show_report_excerpt('procedimentos_duracao.txt', n=15)\n",
    "show_report_excerpt('escala_bloco.csv', n=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
